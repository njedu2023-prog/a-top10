#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
tools/debug_print_snapshot.py

âœ… æ—è·¯è°ƒè¯•å·¥å…·ï¼ˆç¨³å®šç‰ˆï¼‰ï¼š
- ä¸ä¿®æ”¹ä»»ä½• step æ–‡ä»¶
- å•ç‹¬è¿è¡Œå³å¯æ‰“å° pipeline å„é˜¶æ®µè¾“å‡º
- å…¼å®¹æ–‡ä»¶ç¼ºå¤± / ç©ºæ–‡ä»¶ / ç¼–ç å¼‚å¸¸ / åˆ†éš”ç¬¦å¼‚å¸¸ï¼ˆcsv/tsvï¼‰

ç”¨æ³•ï¼š
  python tools/debug_print_snapshot.py
å¯é€‰ï¼š
  python tools/debug_print_snapshot.py --n 20
  python tools/debug_print_snapshot.py --dir outputs
  python tools/debug_print_snapshot.py --md outputs/debug_snapshot.md
"""

from __future__ import annotations

import argparse
from pathlib import Path
from typing import Optional, Tuple

import pandas as pd


# ===========================
# é»˜è®¤è¾“å‡ºæ–‡ä»¶ï¼ˆå¯é€šè¿‡å‚æ•°è¦†ç›–ï¼‰
# ===========================
DEFAULT_OUTPUT_DIR = Path("outputs")

DEFAULT_FILES = {
    "Step2 Candidate Poolï¼ˆå€™é€‰æ¶¨åœæ± ï¼‰": "step2_candidates.csv",
    "Step3 StrengthScore è¾“å‡ºï¼ˆå¼ºåº¦è¯„åˆ†ï¼‰": "step3_strength.csv",
    "Final Top10 è¾“å‡ºï¼ˆæœ€ç»ˆæ¦œå•ï¼‰": "predict_top10_latest.csv",
}


# ===========================
# è¯»æ–‡ä»¶ï¼šå°½é‡ç¨³
# ===========================
def _read_csv_safely(path: Path) -> Tuple[Optional[pd.DataFrame], str]:
    """
    å°½åŠ›è¯»å– CSV/TSVï¼š
    - è‡ªåŠ¨å°è¯• utf-8-sig / utf-8 / gbk
    - è‡ªåŠ¨å°è¯•åˆ†éš”ç¬¦ï¼š,  \\t  ;
    è¿”å› (df, msg)ã€‚df ä¸º None è¡¨ç¤ºå¤±è´¥ã€‚
    """
    if not path.exists():
        return None, f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨ï¼š{path}"

    if path.stat().st_size == 0:
        return None, f"âš ï¸ æ–‡ä»¶ä¸ºç©ºï¼š{path}"

    encodings = ["utf-8-sig", "utf-8", "gbk"]
    seps = [",", "\t", ";"]

    last_err: Optional[Exception] = None
    for enc in encodings:
        for sep in seps:
            try:
                df = pd.read_csv(path, encoding=enc, sep=sep, engine="python")

                # æœ‰äº›æ–‡ä»¶è¯»å‡ºæ¥åªæœ‰ 1 åˆ—ä¸”åˆ—ååƒæ•´è¡Œï¼Œæ¢åˆ†éš”ç¬¦å†è¯•
                if df.shape[1] == 1 and df.columns.size == 1:
                    col0 = str(df.columns[0])
                    if any(s in col0 for s in [",", "\t", ";"]):
                        continue

                return df, f"âœ… è¯»å–æˆåŠŸï¼š{path.name}ï¼ˆencoding={enc}, sep={repr(sep)}ï¼‰"
            except Exception as e:
                last_err = e

    return None, f"âŒ è¯»å–å¤±è´¥ï¼š{path}ï¼ˆæœ€åé”™è¯¯ï¼š{last_err}ï¼‰"


# ===========================
# æ‰“å°ï¼šå¯è¯»ã€å¯æ§
# ===========================
def _maybe_sort(df: pd.DataFrame) -> pd.DataFrame:
    """
    å¦‚æœæœ‰å¸¸è§åˆ—ï¼Œå°±åšä¸€ä¸ªè½»é‡æ’åºï¼Œä¾¿äºè‚‰çœ¼å¯¹æ¯”ã€‚
    è§„åˆ™ï¼š
    - rank/æ’å/ts_code/è‚¡ç¥¨ä»£ç ï¼šå‡åº
    - score/prob/StrengthScore ç­‰ï¼šé™åº
    """
    if df is None or df.empty:
        return df

    # ä½ å¯èƒ½ä¼šé‡åˆ°çš„å¸¸è§åˆ—
    prefer_cols = [
        "rank", "æ’å",
        "ts_code", "è‚¡ç¥¨ä»£ç ",
        "StrengthScore", "å¼ºåº¦å¾—åˆ†",
        "prob", "æ¶¨åœæ¦‚ç‡",
        "_score", "score", "ç»¼åˆå¾—åˆ†",
    ]

    sort_cols = [c for c in prefer_cols if c in df.columns]
    if not sort_cols:
        return df

    # å»é‡ä¿æŒé¡ºåº
    seen = set()
    uniq_cols = []
    for c in sort_cols:
        if c not in seen:
            uniq_cols.append(c)
            seen.add(c)

    def _asc_for(col: str) -> bool:
        key = col.lower()
        # â€œæ’å / rank / codeâ€è¿™ç±»é€šå¸¸å‡åº
        if col in ("rank", "æ’å", "ts_code", "è‚¡ç¥¨ä»£ç "):
            return True
        if "rank" in key or "code" in key:
            return True
        # å…¶ä½™é»˜è®¤æŒ‰â€œåˆ†æ•°/æ¦‚ç‡â€é™åº
        return False

    ascending = [_asc_for(c) for c in uniq_cols]

    try:
        return df.sort_values(by=uniq_cols, ascending=ascending)
    except Exception:
        return df


def _print_df(title: str, df: Optional[pd.DataFrame], n: int = 10, max_colwidth: int = 32) -> str:
    """
    æ‰“å°å¹¶è¿”å›åŒæ ·å†…å®¹çš„å­—ç¬¦ä¸²ï¼ˆæ–¹ä¾¿å†™å…¥ markdownï¼‰ã€‚
    """
    lines = []
    lines.append("\n" + "=" * 78)
    lines.append(f"ğŸ“Œ {title}")
    lines.append("=" * 78)

    if df is None:
        lines.append("ï¼ˆæ— æ•°æ®ï¼‰")
        out = "\n".join(lines)
        print(out)
        return out

    if df.empty:
        lines.append("ï¼ˆDataFrame ä¸ºç©ºï¼‰")
        out = "\n".join(lines)
        print(out)
        return out

    df2 = _maybe_sort(df.copy())

    # æˆªæ–­è¶…é•¿å­—æ®µï¼Œé¿å…åˆ·å±
    def _truncate(x):
        s = "" if pd.isna(x) else str(x)
        if len(s) > max_colwidth:
            return s[: max_colwidth - 1] + "â€¦"
        return s

    try:
        for col in df2.columns:
            if df2[col].dtype == "object":
                df2[col] = df2[col].map(_truncate)
    except Exception:
        pass

    with pd.option_context(
        "display.max_rows", n,
        "display.max_columns", 200,
        "display.width", 220,
        "display.max_colwidth", max_colwidth,
    ):
        head_txt = df2.head(n).to_string(index=False)
        lines.append(head_txt)
        lines.append(f"\nâœ… æ€»è¡Œæ•°: {len(df2)}")
        lines.append(f"âœ… åˆ—æ•°: {len(df2.columns)}")
        lines.append(f"âœ… åˆ—å: {list(df2.columns)}")

    out = "\n".join(lines)
    print(out)
    return out


def _to_markdown_block(title: str, df: Optional[pd.DataFrame], n: int = 10) -> str:
    """
    è¾“å‡ºä¸€ä¸ª markdown ç‰‡æ®µï¼ˆè¡¨æ ¼å½¢å¼ï¼Œé€‚åˆæ”¾åˆ° md æ–‡ä»¶é‡Œï¼‰
    """
    md = []
    md.append(f"\n## {title}\n")

    if df is None:
        md.append("> ï¼ˆæ— æ•°æ®ï¼‰\n")
        return "".join(md)

    if df.empty:
        md.append("> ï¼ˆDataFrame ä¸ºç©ºï¼‰\n")
        return "".join(md)

    df2 = _maybe_sort(df.copy()).head(n)
    try:
        md.append(df2.to_markdown(index=False))
        md.append("\n")
        md.append(f"\n- æ€»è¡Œæ•°ï¼š{len(df)}\n")
        md.append(f"- åˆ—åï¼š{list(df.columns)}\n")
    except Exception:
        # to_markdown ä¾èµ– tabulateï¼›å¦‚æœæ²¡è£…ï¼Œå›é€€æˆçº¯æ–‡æœ¬
        md.append("```text\n")
        md.append(df2.to_string(index=False))
        md.append("\n```\n")
        md.append(f"\n- æ€»è¡Œæ•°ï¼š{len(df)}\n")
        md.append(f"- åˆ—åï¼š{list(df.columns)}\n")

    return "".join(md)


# ===========================
# ä¸»å…¥å£
# ===========================
def main() -> int:
    parser = argparse.ArgumentParser(description="Top10 ç³»ç»Ÿæ—è·¯è°ƒè¯•æ‰“å°å™¨ï¼ˆç¨³å®šç‰ˆï¼‰")
    parser.add_argument("--dir", type=str, default=str(DEFAULT_OUTPUT_DIR), help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ outputsï¼‰")
    parser.add_argument("--n", type=int, default=10, help="æ¯ä¸ªè¡¨æ‰“å°å‰ N è¡Œï¼ˆé»˜è®¤ 10ï¼‰")
    parser.add_argument("--max-colwidth", type=int, default=32, help="å­—ç¬¦ä¸²åˆ—æœ€å¤§æ˜¾ç¤ºå®½åº¦ï¼ˆé»˜è®¤ 32ï¼‰")
    parser.add_argument("--md", type=str, default="", help="å¯é€‰ï¼šå†™å…¥ markdown æ–‡ä»¶è·¯å¾„")
    args = parser.parse_args()

    out_dir = Path(args.dir)
    n = max(1, int(args.n))
    max_colwidth = max(8, int(args.max_colwidth))

    print("\nâœ… Top10 ç³»ç»Ÿæ—è·¯è°ƒè¯•æ‰“å°å™¨å¯åŠ¨...\n")
    print(f"ğŸ“ è¾“å‡ºç›®å½•ï¼š{out_dir.resolve()}")
    print(f"ğŸ” æ¯è¡¨æ˜¾ç¤ºè¡Œæ•°ï¼š{n}\n")

    md_parts = []
    if args.md:
        md_parts.append(f"# Top10 Debug Snapshot\n\n- è¾“å‡ºç›®å½•ï¼š`{out_dir}`\n- æ¯è¡¨æ˜¾ç¤ºï¼šå‰ {n} è¡Œ\n")

    for title, fname in DEFAULT_FILES.items():
        path = out_dir / fname
        df, msg = _read_csv_safely(path)
        print(msg)

        _print_df(title, df, n=n, max_colwidth=max_colwidth)

        if args.md:
            md_parts.append(_to_markdown_block(title, df, n=n))

    if args.md:
        md_path = Path(args.md)
        try:
            md_path.parent.mkdir(parents=True, exist_ok=True)
            md_path.write_text("".join(md_parts), encoding="utf-8")
            print(f"\nğŸ“ å·²å†™å…¥ Markdownï¼š{md_path.resolve()}\n")
        except Exception as e:
            print(f"\nâš ï¸ å†™å…¥ Markdown å¤±è´¥ï¼š{e}\n")

    print("\nâœ… æ—è·¯è°ƒè¯•ç»“æŸã€‚\n")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
