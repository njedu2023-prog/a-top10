name: Run Top10 Engine (Auto Daily)

on:
  schedule:
    - cron: "5 11 * * 1-5"
    - cron: "35 11 * * 1-5"

  # 手动运行：可指定 trade_date
  workflow_dispatch:
    inputs:
      trade_date:
        description: "指定交易日 YYYYMMDD（留空=自动寻找最新）"
        required: false
        type: string

permissions:
  contents: write

concurrency:
  group: top10-daily
  cancel-in-progress: false

jobs:
  run:
    runs-on: ubuntu-latest

    env:
      TZ: Asia/Shanghai
      PYTHONUTF8: "1"

      # ✅ 关键：secret 名为 A_TOP10_TOKEN，这里桥接到程序读取的 TUSHARE_TOKEN
      TUSHARE_TOKEN: ${{ secrets.A_TOP10_TOKEN }}

      # ---- 数据仓库信息（方案二：只用 raw，不用 GitHub API）----
      DATA_GITHUB_USER: njedu2023-prog
      DATA_REPO: a-share-top3-data
      DATA_BRANCH: main

      # ---- 与 configs/default.yml 对齐（warehouse_root / repo_name / raw_dir）----
      WAREHOUSE_ROOT: _warehouse
      RAW_DIR: data/raw

      # ---- ✅ 全量快照文件清单（按 data/raw/YYYY/YYYYMMDD/ 内实际文件名）----
      FILES: >-
        _meta.json
        daily.csv
        daily_basic.csv
        hot_boards.csv
        limit_break_d.csv
        limit_list_d.csv
        limit_up_tags.csv
        moneyflow_hsgt.csv
        namechange.csv
        stk_limit.csv
        stock_basic.csv
        top_list.csv

      # ---- ✅ 必须存在的关键文件（缺任何一个都直接失败）----
      REQUIRED_FILES: >-
        daily.csv
        daily_basic.csv
        limit_list_d.csv
        hot_boards.csv
        top_list.csv
        limit_up_tags.csv

      # ---- 自动回溯天数（找最近一个有数据的交易日目录）----
      LOOKBACK_DAYS: "20"

      # ---- 用于探测数据是否存在的哨兵文件 ----
      PROBE_FILE: "daily.csv"

    steps:
      - name: Checkout engine repo (a-top10)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi

          # ✅ writers 需要 tabulate
          pip install -U tabulate

          # ✅ Step7 需要 lightgbm（否则永远无法生成 step5_lgbm.joblib）
          pip install -U lightgbm

      - name: Resolve trade_date (manual or auto)
        id: resolve_date
        shell: bash
        run: |
          set -euo pipefail

          MANUAL="${{ github.event.inputs.trade_date || '' }}"
          if [ -n "$MANUAL" ]; then
            echo "Use manual trade_date=$MANUAL"
            echo "trade_date=$MANUAL" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          echo "Auto resolve latest snapshot trade_date"
          today="$(date +%Y%m%d)"
          base="https://raw.githubusercontent.com/${DATA_GITHUB_USER}/${DATA_REPO}/${DATA_BRANCH}/${RAW_DIR}"

          found=""
          for i in $(seq 0 "$LOOKBACK_DAYS"); do
            d="$(date -d "${today} -${i} day" +%Y%m%d)"
            y="${d:0:4}"
            url="${base}/${y}/${d}/${PROBE_FILE}"

            code="$(curl -s -o /dev/null -w "%{http_code}" -I "$url" || true)"
            echo "[probe] ${d} => ${code}"

            if [ "$code" = "200" ]; then
              found="$d"
              break
            fi
          done

          if [ -z "$found" ]; then
            echo "ERROR: cannot find any snapshot within last ${LOOKBACK_DAYS} days"
            exit 2
          fi

          echo "Resolved trade_date=$found"
          echo "trade_date=$found" >> "$GITHUB_OUTPUT"

      - name: Download snapshot files to warehouse (raw, full)
        shell: bash
        run: |
          set -euo pipefail

          trade_date="${{ steps.resolve_date.outputs.trade_date }}"
          year="${trade_date:0:4}"

          dest="${WAREHOUSE_ROOT}/${DATA_REPO}/${RAW_DIR}/${year}/${trade_date}"
          mkdir -p "$dest"

          base="https://raw.githubusercontent.com/${DATA_GITHUB_USER}/${DATA_REPO}/${DATA_BRANCH}/${RAW_DIR}/${year}/${trade_date}"

          echo "Downloading to: $dest"
          echo "Base URL: $base"
          echo "FILES: $FILES"
          echo "REQUIRED_FILES: $REQUIRED_FILES"

          missing_required=""

          for f in $FILES; do
            url="${base}/${f}"
            out="${dest}/${f}"
            echo "[get] $url"
            if curl -fL --retry 3 --retry-delay 1 -o "$out" "$url"; then
              ls -lh "$out" || true
            else
              echo "WARN: missing or cannot download: $f"
              rm -f "$out" || true
            fi
          done

          for rf in $REQUIRED_FILES; do
            p="${dest}/${rf}"
            if [ ! -s "$p" ]; then
              echo "ERROR: required snapshot file missing/empty: $rf"
              missing_required="${missing_required} ${rf}"
            fi
          done

          if [ -n "$missing_required" ]; then
            echo "ERROR: required snapshot files missing:${missing_required}"
            echo "HINT: 如果数据仓库当天确实存在这些文件，说明 raw URL 或路径配置有误。"
            exit 3
          fi

          echo "OK: downloaded FULL snapshots for ${trade_date}"

      - name: Debug warehouse (list)
        shell: bash
        run: |
          set -euo pipefail

          trade_date="${{ steps.resolve_date.outputs.trade_date }}"
          year="${trade_date:0:4}"

          echo "====== LIST _warehouse (top) ======"
          ls -la _warehouse || true

          echo "====== LIST snapshot dir ======"
          ls -la "${WAREHOUSE_ROOT}/${DATA_REPO}/${RAW_DIR}/${year}/${trade_date}" || true

          echo "====== CHECK key files (size) ======"
          du -h "${WAREHOUSE_ROOT}/${DATA_REPO}/${RAW_DIR}/${year}/${trade_date}"/* || true

      - name: Run Top10 Engine + Step7
        shell: bash
        env:
          TRADE_DATE: ${{ steps.resolve_date.outputs.trade_date }}
        run: |
          set -euo pipefail
          echo "Running engine with TRADE_DATE=$TRADE_DATE"

          if [ -f "run.py" ]; then
            python run.py
          else
            python -m a_top10
          fi

          # ✅ Step7：自学习闭环（会写 outputs/learning 报告 + models/*.joblib）
          python -m a_top10.steps.step7_self_learning

      - name: Step7 artifacts check + stamp (always)
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          td="${{ steps.resolve_date.outputs.trade_date }}"
          rid="${{ github.run_id }}"

          echo "====== LIST outputs (top) ======"
          ls -la outputs || true

          echo "====== LIST outputs/learning ======"
          ls -la outputs/learning || true

          echo "====== LIST models (repo root) ======"
          ls -la models || true

          # ✅ 关键：写一个每次必变的哨兵文件，保证你在仓库“看得见 Step7 跑过”
          mkdir -p outputs/learning
          echo "run_id=${rid} trade_date=${td} utc=$(date -u '+%Y-%m-%dT%H:%M:%SZ')" > "outputs/learning/_last_run_${td}_${rid}.txt"
          echo "STAMP written: outputs/learning/_last_run_${td}_${rid}.txt"

      - name: Commit & push outputs + models (always)
        if: always()
        shell: bash
        run: |
          set -euo pipefail

          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          # ✅ 只提交 outputs + models（避免把 _warehouse 等目录误提交）
          git add -A outputs models

          echo "====== git status (after add outputs+models) ======"
          git status --porcelain

          if [ -z "$(git status --porcelain)" ]; then
            echo "No changes to commit."
            exit 0
          fi

          td="${{ steps.resolve_date.outputs.trade_date }}"
          rid="${{ github.run_id }}"

          git commit -m "auto: run top10 ${td} (run=${rid})" || true
          git pull --rebase origin main || true
          git push || true
